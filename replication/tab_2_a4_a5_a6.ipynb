{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a993c4",
   "metadata": {},
   "source": [
    "# The Role of Hyperparameters in Machine Learning Models and How to Tune Them (PSRM, 2023)\n",
    "### Christian Arnold, Luka Biedebach, Andreas KÃ¼pfer, and Marcel Neunhoeffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42d16a",
   "metadata": {},
   "source": [
    "### *Code to replicate information depicted in Table 2, A4, A5, and A6*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f22d43ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaskuepfer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#IMPORTS for Baselines\n",
    "from functions import load_data, preprocess_data, run_svc, run_dummy, run_randomforest, run_naivebayes\n",
    "import numpy as np\n",
    "np.set_printoptions(precision=15)\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import EnglishStemmer, SpanishStemmer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# IMPORTS for CNN\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras_tuner\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling1D, GlobalMaxPooling2D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from keras_tuner import HyperModel, Objective\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, concatenate\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from gensim import models\n",
    "import gensim.downloader as api\n",
    "\n",
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf84eeb",
   "metadata": {},
   "source": [
    "### Naive Bayes, Random Forest, and SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec5ba28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Country: Venezuela\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n",
      "Best Tuning Score is 0.5377622377622379 with params {'svc__C': 1.0, 'svc__class_weight': 'balanced', 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9191090269636577, 0.36585365853658536, 0.6382978723404256, 0.46511627906976744]\n",
      "SVC Untuned...\n",
      "[0.9460726846424384, 0.6666666666666666, 0.0425531914893617, 0.08]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.4862738813474108 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 1000, 'randomforest__random_state': 20211010}\n",
      "[0.9413833528722158, 0.46938775510204084, 0.48936170212765956, 0.47916666666666663]\n",
      "Random Forest Untuned...\n",
      "[0.9472450175849941, 0.5833333333333334, 0.14893617021276595, 0.23728813559322032]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.3306634327631272 with params {'naivebayes__alpha': 0.0015199110829529332}\n",
      "[0.9472450175849941, 0.5555555555555556, 0.2127659574468085, 0.3076923076923077]\n",
      "Naives Bayes Untuned...\n",
      "[0.9449003516998827, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.5411752556444264 with params {'svc__C': 403.4287934927351, 'svc__class_weight': 'balanced', 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9273153575615475, 0.38461538461538464, 0.5319148936170213, 0.44642857142857145]\n",
      "SVC Untuned...\n",
      "[0.9472450175849941, 0.6, 0.1276595744680851, 0.21052631578947367]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.5051955826676062 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 150, 'randomforest__random_state': 20211010}\n",
      "[0.9109026963657679, 0.2542372881355932, 0.3191489361702128, 0.28301886792452835]\n",
      "Random Forest Untuned...\n",
      "[0.9472450175849941, 0.5714285714285714, 0.1702127659574468, 0.2622950819672131]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.3212246301177243 with params {'naivebayes__alpha': 0.001873817422860383}\n",
      "[0.9495896834701055, 0.6, 0.2553191489361702, 0.3582089552238805]\n",
      "Naives Bayes Untuned...\n",
      "[0.9449003516998827, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n",
      "Best Tuning Score is 0.5583062790591106 with params {'svc__C': 1.0, 'svc__class_weight': 'balanced', 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9320046893317703, 0.42028985507246375, 0.6170212765957447, 0.5]\n",
      "SVC Untuned...\n",
      "[0.9460726846424384, 0.6, 0.06382978723404255, 0.11538461538461536]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.46898123119683577 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 400, 'randomforest__random_state': 20211010}\n",
      "[0.9472450175849941, 0.5217391304347826, 0.5106382978723404, 0.5161290322580645]\n",
      "Random Forest Untuned...\n",
      "[0.9472450175849941, 0.5833333333333334, 0.14893617021276595, 0.23728813559322032]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.3474681000673745 with params {'naivebayes__alpha': 0.003511191734215131}\n",
      "[0.9507620164126612, 0.6470588235294118, 0.23404255319148937, 0.34375]\n",
      "Naives Bayes Untuned...\n",
      "[0.9449003516998827, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.4989018138177184 with params {'svc__C': 148.4131591025766, 'svc__class_weight': 'balanced', 'svc__gamma': 'auto', 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9296600234466589, 0.41975308641975306, 0.723404255319149, 0.53125]\n",
      "SVC Untuned...\n",
      "[0.9531066822977726, 0.8181818181818182, 0.19148936170212766, 0.31034482758620685]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.4859400053652738 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 400, 'randomforest__random_state': 20211010}\n",
      "[0.936694021101993, 0.4406779661016949, 0.5531914893617021, 0.49056603773584906]\n",
      "Random Forest Untuned...\n",
      "[0.9507620164126612, 0.6923076923076923, 0.19148936170212766, 0.30000000000000004]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.29013453392774535 with params {'naivebayes__alpha': 0.01873817422860384}\n",
      "[0.9542790152403282, 0.6428571428571429, 0.3829787234042553, 0.48]\n",
      "Naives Bayes Untuned...\n",
      "[0.9449003516998827, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.5268164678152867 with params {'svc__C': 54.598150033144236, 'svc__class_weight': 'balanced', 'svc__gamma': 0.001, 'svc__kernel': 'sigmoid', 'svc__random_state': 20211010}\n",
      "[0.9378663540445487, 0.45714285714285713, 0.6808510638297872, 0.547008547008547]\n",
      "SVC Untuned...\n",
      "[0.9507620164126612, 1.0, 0.10638297872340426, 0.1923076923076923]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.4797324361131138 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 200, 'randomforest__random_state': 20211010}\n",
      "[0.9320046893317703, 0.39622641509433965, 0.44680851063829785, 0.42000000000000004]\n",
      "Random Forest Untuned...\n",
      "[0.9531066822977726, 0.8888888888888888, 0.1702127659574468, 0.2857142857142857]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.3397329168721574 with params {'naivebayes__alpha': 0.004328761281083057}\n",
      "[0.9531066822977726, 0.7692307692307693, 0.2127659574468085, 0.33333333333333337]\n",
      "Naives Bayes Untuned...\n",
      "[0.9449003516998827, 0.0, 0.0, 0.0]\n",
      "\n",
      "Current Country: Ghana\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n",
      "Best Tuning Score is 0.674169622806332 with params {'svc__C': 20.085536923187668, 'svc__class_weight': 'balanced', 'svc__gamma': 0.01, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9645669291338582, 0.7058823529411765, 0.75, 0.7272727272727272]\n",
      "SVC Untuned...\n",
      "[0.9488188976377953, 0.8, 0.25, 0.38095238095238093]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.5991022914367862 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 100, 'randomforest__random_state': 20211010}\n",
      "[0.9507874015748031, 0.6129032258064516, 0.59375, 0.6031746031746031]\n",
      "Random Forest Untuned...\n",
      "[0.9468503937007874, 0.7777777777777778, 0.21875, 0.34146341463414637]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.5118148872990834 with params {'naivebayes__alpha': 6.579332246575683e-06}\n",
      "[0.952755905511811, 0.7, 0.4375, 0.5384615384615384]\n",
      "Naives Bayes Untuned...\n",
      "[0.937007874015748, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.6661288515406163 with params {'svc__C': 2980.9579870417283, 'svc__class_weight': 'balanced', 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9468503937007874, 0.5714285714285714, 0.625, 0.5970149253731343]\n",
      "SVC Untuned...\n",
      "[0.9547244094488189, 0.8461538461538461, 0.34375, 0.4888888888888889]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.5919452225334578 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 200, 'randomforest__random_state': 20211010}\n",
      "[0.9251968503937008, 0.425, 0.53125, 0.47222222222222215]\n",
      "Random Forest Untuned...\n",
      "[0.952755905511811, 0.7857142857142857, 0.34375, 0.4782608695652174]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.4574571811167556 with params {'naivebayes__alpha': 8.111308307896872e-07}\n",
      "[0.9566929133858267, 0.8571428571428571, 0.375, 0.5217391304347825]\n",
      "Naives Bayes Untuned...\n",
      "[0.937007874015748, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.6566268242940857 with params {'svc__C': 2.718281828459045, 'svc__class_weight': 'balanced', 'svc__gamma': 0.1, 'svc__kernel': 'sigmoid', 'svc__random_state': 20211010}\n",
      "[0.9330708661417323, 0.4807692307692308, 0.78125, 0.5952380952380952]\n",
      "SVC Untuned...\n",
      "[0.9409448818897638, 0.5833333333333334, 0.21875, 0.31818181818181823]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.610888455482305 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 150, 'randomforest__random_state': 20211010}\n",
      "[0.9389763779527559, 0.5135135135135135, 0.59375, 0.5507246376811593]\n",
      "Random Forest Untuned...\n",
      "[0.9330708661417323, 0.4, 0.125, 0.19047619047619047]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.45180690540538393 with params {'naivebayes__alpha': 5.336699231206313e-06}\n",
      "[0.9389763779527559, 0.5238095238095238, 0.34375, 0.4150943396226415]\n",
      "Naives Bayes Untuned...\n",
      "[0.937007874015748, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.6711242142276626 with params {'svc__C': 148.4131591025766, 'svc__class_weight': 'balanced', 'svc__gamma': 0.001, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9291338582677166, 0.46, 0.71875, 0.5609756097560976]\n",
      "SVC Untuned...\n",
      "[0.9606299212598425, 0.9285714285714286, 0.40625, 0.5652173913043478]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.5812121212121213 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 150, 'randomforest__random_state': 20211010}\n",
      "[0.9251968503937008, 0.4318181818181818, 0.59375, 0.5]\n",
      "Random Forest Untuned...\n",
      "[0.9566929133858267, 0.9166666666666666, 0.34375, 0.5]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.44381353299699 with params {'naivebayes__alpha': 3.5111917342151275e-06}\n",
      "[0.9586614173228346, 0.72, 0.5625, 0.631578947368421]\n",
      "Naives Bayes Untuned...\n",
      "[0.937007874015748, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.683830113241878 with params {'svc__C': 20.085536923187668, 'svc__class_weight': 'balanced', 'svc__gamma': 0.01, 'svc__kernel': 'sigmoid', 'svc__random_state': 20211010}\n",
      "[0.9468503937007874, 0.5581395348837209, 0.75, 0.6399999999999999]\n",
      "SVC Untuned...\n",
      "[0.9468503937007874, 0.7272727272727273, 0.25, 0.37209302325581395]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.5973762010347375 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 400, 'randomforest__random_state': 20211010}\n",
      "[0.9409448818897638, 0.5294117647058824, 0.5625, 0.5454545454545455]\n",
      "Random Forest Untuned...\n",
      "[0.9429133858267716, 0.6363636363636364, 0.21875, 0.3255813953488372]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.4561482540483466 with params {'naivebayes__alpha': 6.579332246575682e-08}\n",
      "[0.9507874015748031, 0.7333333333333333, 0.34375, 0.4680851063829787]\n",
      "Naives Bayes Untuned...\n",
      "[0.937007874015748, 0.0, 0.0, 0.0]\n",
      "\n",
      "Current Country: Philippines\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n",
      "Best Tuning Score is 0.5206484731931174 with params {'svc__C': 2980.9579870417283, 'svc__class_weight': 'balanced', 'svc__gamma': 0.0001, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.948559670781893, 0.47058823529411764, 0.6956521739130435, 0.5614035087719297]\n",
      "SVC Untuned...\n",
      "[0.9629629629629629, 1.0, 0.21739130434782608, 0.3571428571428571]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.46231702510772277 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 1, 'randomforest__max_features': 'log2', 'randomforest__n_estimators': 400, 'randomforest__random_state': 20211010}\n",
      "[0.9567901234567902, 1.0, 0.08695652173913043, 0.16]\n",
      "Random Forest Untuned...\n",
      "[0.9629629629629629, 0.8571428571428571, 0.2608695652173913, 0.4]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.48155553301894766 with params {'naivebayes__alpha': 1.873817422860383e-05}\n",
      "[0.948559670781893, 0.4444444444444444, 0.34782608695652173, 0.3902439024390244]\n",
      "Naives Bayes Untuned...\n",
      "[0.9526748971193416, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.5513322884012538 with params {'svc__C': 148.4131591025766, 'svc__class_weight': None, 'svc__gamma': 0.01, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9609053497942387, 0.7, 0.30434782608695654, 0.42424242424242425]\n",
      "SVC Untuned...\n",
      "[0.9567901234567902, 0.75, 0.13043478260869565, 0.22222222222222218]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.4721958501268846 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 1000, 'randomforest__random_state': 20211010}\n",
      "[0.9423868312757202, 0.4, 0.43478260869565216, 0.41666666666666663]\n",
      "Random Forest Untuned...\n",
      "[0.9526748971193416, 0.5, 0.13043478260869565, 0.20689655172413793]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.4487388916930513 with params {'naivebayes__alpha': 1e-08}\n",
      "[0.9547325102880658, 0.5333333333333333, 0.34782608695652173, 0.4210526315789474]\n",
      "Naives Bayes Untuned...\n",
      "[0.9547325102880658, 1.0, 0.043478260869565216, 0.08333333333333333]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n",
      "Best Tuning Score is 0.5692680865449627 with params {'svc__C': 2980.9579870417283, 'svc__class_weight': None, 'svc__gamma': 0.001, 'svc__kernel': 'sigmoid', 'svc__random_state': 20211010}\n",
      "[0.9567901234567902, 0.5555555555555556, 0.43478260869565216, 0.4878048780487805]\n",
      "SVC Untuned...\n",
      "[0.9567901234567902, 0.6666666666666666, 0.17391304347826086, 0.27586206896551724]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.5169238019136599 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'log2', 'randomforest__n_estimators': 1000, 'randomforest__random_state': 20211010}\n",
      "[0.9403292181069959, 0.3125, 0.21739130434782608, 0.2564102564102564]\n",
      "Random Forest Untuned...\n",
      "[0.948559670781893, 0.375, 0.13043478260869565, 0.19354838709677416]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.46465746676272995 with params {'naivebayes__alpha': 1.519911082952933e-09}\n",
      "[0.948559670781893, 0.42857142857142855, 0.2608695652173913, 0.3243243243243243]\n",
      "Naives Bayes Untuned...\n",
      "[0.9567901234567902, 1.0, 0.08695652173913043, 0.16]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n",
      "Best Tuning Score is 0.5474415463034958 with params {'svc__C': 20.085536923187668, 'svc__class_weight': 'balanced', 'svc__gamma': 0.01, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9444444444444444, 0.4444444444444444, 0.6956521739130435, 0.5423728813559322]\n",
      "SVC Untuned...\n",
      "[0.9650205761316872, 0.875, 0.30434782608695654, 0.4516129032258065]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.45933205657343584 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 150, 'randomforest__random_state': 20211010}\n",
      "[0.9465020576131687, 0.44, 0.4782608695652174, 0.4583333333333333]\n",
      "Random Forest Untuned...\n",
      "[0.9629629629629629, 0.7777777777777778, 0.30434782608695654, 0.43750000000000006]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.44759878299351985 with params {'naivebayes__alpha': 1e-05}\n",
      "[0.9588477366255144, 0.6, 0.391304347826087, 0.47368421052631576]\n",
      "Naives Bayes Untuned...\n",
      "[0.9526748971193416, 0.0, 0.0, 0.0]\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreaskuepfer/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1327: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Tuning Score is 0.5495726495726496 with params {'svc__C': 20.085536923187668, 'svc__class_weight': 'balanced', 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9567901234567902, 0.55, 0.4782608695652174, 0.5116279069767442]\n",
      "SVC Untuned...\n",
      "[0.9588477366255144, 0.8, 0.17391304347826086, 0.2857142857142857]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n",
      "Best Tuning Score is 0.46595481227834173 with params {'randomforest__class_weight': 'balanced', 'randomforest__max_depth': 5, 'randomforest__max_features': 'sqrt', 'randomforest__n_estimators': 100, 'randomforest__random_state': 20211010}\n",
      "[0.9444444444444444, 0.4, 0.34782608695652173, 0.37209302325581395]\n",
      "Random Forest Untuned...\n",
      "[0.9650205761316872, 0.875, 0.30434782608695654, 0.4516129032258065]\n",
      "Naives Bayes...\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best Tuning Score is 0.4617736365801381 with params {'naivebayes__alpha': 1.2328467394420635e-09}\n",
      "[0.9629629629629629, 0.6666666666666666, 0.43478260869565216, 0.5263157894736841]\n",
      "Naives Bayes Untuned...\n",
      "[0.9567901234567902, 1.0, 0.08695652173913043, 0.16]\n",
      "      Baseline      Country  Accuracy  Precision    Recall        F1\n",
      "0          SVM    Venezuela  0.919109   0.365854  0.638298  0.465116\n",
      "1  SVM Untuned    Venezuela  0.946073   0.666667  0.042553  0.080000\n",
      "2          SVM        Ghana  0.964567   0.705882  0.750000  0.727273\n",
      "3  SVM Untuned        Ghana  0.948819   0.800000  0.250000  0.380952\n",
      "4          SVM  Philippines  0.948560   0.470588  0.695652  0.561404\n",
      "5  SVM Untuned  Philippines  0.962963   1.000000  0.217391  0.357143\n",
      "                Baseline      Country  Accuracy  Precision    Recall        F1\n",
      "0          Random Forest    Venezuela  0.941383   0.469388  0.489362  0.479167\n",
      "1  Random Forest Untuned    Venezuela  0.947245   0.583333  0.148936  0.237288\n",
      "2          Random Forest        Ghana  0.950787   0.612903  0.593750  0.603175\n",
      "3  Random Forest Untuned        Ghana  0.946850   0.777778  0.218750  0.341463\n",
      "4          Random Forest  Philippines  0.956790   1.000000  0.086957  0.160000\n",
      "5  Random Forest Untuned  Philippines  0.962963   0.857143  0.260870  0.400000\n",
      "              Baseline      Country  Accuracy  Precision    Recall        F1\n",
      "0          Naive Bayes    Venezuela  0.947245   0.555556  0.212766  0.307692\n",
      "1  Naive Bayes Untuned    Venezuela  0.944900   0.000000  0.000000  0.000000\n",
      "2          Naive Bayes        Ghana  0.952756   0.700000  0.437500  0.538462\n",
      "3  Naive Bayes Untuned        Ghana  0.937008   0.000000  0.000000  0.000000\n",
      "4          Naive Bayes  Philippines  0.948560   0.444444  0.347826  0.390244\n",
      "5  Naive Bayes Untuned  Philippines  0.952675   0.000000  0.000000  0.000000\n",
      "        Country   kernel            C class_weight   gamma  Tuning F1  \\\n",
      "0     Venezuela      rbf     1.000000     balanced     0.1   0.537762   \n",
      "1     Venezuela      rbf   403.428793     balanced  0.0001   0.541175   \n",
      "2     Venezuela      rbf     1.000000     balanced     0.1   0.558306   \n",
      "3     Venezuela      rbf   148.413159     balanced    auto   0.498902   \n",
      "4     Venezuela  sigmoid    54.598150     balanced   0.001   0.526816   \n",
      "5         Ghana      rbf    20.085537     balanced    0.01   0.674170   \n",
      "6         Ghana      rbf  2980.957987     balanced  0.0001   0.666129   \n",
      "7         Ghana  sigmoid     2.718282     balanced     0.1   0.656627   \n",
      "8         Ghana      rbf   148.413159     balanced   0.001   0.671124   \n",
      "9         Ghana  sigmoid    20.085537     balanced    0.01   0.683830   \n",
      "10  Philippines      rbf  2980.957987     balanced  0.0001   0.520648   \n",
      "11  Philippines      rbf   148.413159         None    0.01   0.551332   \n",
      "12  Philippines  sigmoid  2980.957987         None   0.001   0.569268   \n",
      "13  Philippines      rbf    20.085537     balanced    0.01   0.547442   \n",
      "14  Philippines      rbf    20.085537     balanced     0.1   0.549573   \n",
      "\n",
      "      OOS F1  \n",
      "0   0.465116  \n",
      "1   0.446429  \n",
      "2   0.500000  \n",
      "3   0.531250  \n",
      "4   0.547009  \n",
      "5   0.727273  \n",
      "6   0.597015  \n",
      "7   0.595238  \n",
      "8   0.560976  \n",
      "9   0.640000  \n",
      "10  0.561404  \n",
      "11  0.424242  \n",
      "12  0.487805  \n",
      "13  0.542373  \n",
      "14  0.511628  \n",
      "        Country max_depth n_estimators class_weight max_features  Tuning F1  \\\n",
      "0     Venezuela         5         1000     balanced         sqrt   0.486274   \n",
      "1     Venezuela         5          150     balanced         sqrt   0.505196   \n",
      "2     Venezuela         5          400     balanced         sqrt   0.468981   \n",
      "3     Venezuela         5          400     balanced         sqrt   0.485940   \n",
      "4     Venezuela         5          200     balanced         sqrt   0.479732   \n",
      "5         Ghana         5          100     balanced         sqrt   0.599102   \n",
      "6         Ghana         5          200     balanced         sqrt   0.591945   \n",
      "7         Ghana         5          150     balanced         sqrt   0.610888   \n",
      "8         Ghana         5          150     balanced         sqrt   0.581212   \n",
      "9         Ghana         5          400     balanced         sqrt   0.597376   \n",
      "10  Philippines         1          400     balanced         log2   0.462317   \n",
      "11  Philippines         5         1000     balanced         sqrt   0.472196   \n",
      "12  Philippines         5         1000     balanced         log2   0.516924   \n",
      "13  Philippines         5          150     balanced         sqrt   0.459332   \n",
      "14  Philippines         5          100     balanced         sqrt   0.465955   \n",
      "\n",
      "      OOS F1  \n",
      "0   0.479167  \n",
      "1   0.283019  \n",
      "2   0.516129  \n",
      "3   0.490566  \n",
      "4   0.420000  \n",
      "5   0.603175  \n",
      "6   0.472222  \n",
      "7   0.550725  \n",
      "8   0.500000  \n",
      "9   0.545455  \n",
      "10  0.160000  \n",
      "11  0.416667  \n",
      "12  0.256410  \n",
      "13  0.458333  \n",
      "14  0.372093  \n",
      "        Country         alpha  Tuning F1    OOS F1\n",
      "0     Venezuela  1.519911e-03   0.330663  0.307692\n",
      "1     Venezuela  1.873817e-03   0.321225  0.358209\n",
      "2     Venezuela  3.511192e-03   0.347468  0.343750\n",
      "3     Venezuela  1.873817e-02   0.290135  0.480000\n",
      "4     Venezuela  4.328761e-03   0.339733  0.333333\n",
      "5         Ghana  6.579332e-06   0.511815  0.538462\n",
      "6         Ghana  8.111308e-07   0.457457  0.521739\n",
      "7         Ghana  5.336699e-06   0.451807  0.415094\n",
      "8         Ghana  3.511192e-06   0.443814  0.631579\n",
      "9         Ghana  6.579332e-08   0.456148  0.468085\n",
      "10  Philippines  1.873817e-05   0.481556  0.390244\n",
      "11  Philippines  1.000000e-08   0.448739  0.421053\n",
      "12  Philippines  1.519911e-09   0.464657  0.324324\n",
      "13  Philippines  1.000000e-05   0.447599  0.473684\n",
      "14  Philippines  1.232847e-09   0.461774  0.526316\n"
     ]
    }
   ],
   "source": [
    "# set 5 different seeds for reproducibility\n",
    "seeds = [20210101, 20210102, 20210103, 20210104, 20210105]\n",
    "\n",
    "# initialize dictionary for countries/datasets\n",
    "countries = {\"Venezuela\": \"raw/vz-tweets_full.csv\", \"Ghana\": \"raw/gh-tweets_full.csv\", \"Philippines\": \"raw/ph-tweets_full.csv\"}\n",
    "\n",
    "# define dataframe to store results\n",
    "results_svc = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "results_svc_full = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "results_randomforest = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "results_randomforest_full = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "results_naivebayes = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "results_naivebayes_full = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "results_tuning_svc = pd.DataFrame(columns=[\"Country\", \"kernel\", \"C\", \"class_weight\", \"gamma\", \"Tuning F1\", \"OOS F1\"])\n",
    "results_tuning_randomforest = pd.DataFrame(columns=[\"Country\", \"max_depth\", \"n_estimators\", \"class_weight\", \"max_features\", \"Tuning F1\", \"OOS F1\"])\n",
    "results_tuning_naivebayes = pd.DataFrame(columns=[\"Country\", \"alpha\", \"Tuning F1\", \"OOS F1\"])\n",
    "\n",
    "# loop over all countries\n",
    "\n",
    "for country, path in countries.items():\n",
    "    print(\"\\nCurrent Country: \" + country)\n",
    "    # initialize stopwords and stemmer in correct language\n",
    "    stops = set(stopwords.words(\"spanish\")) if country == \"Venezuela\" else set(stopwords.words(\"english\"))\n",
    "    stemmer = SpanishStemmer() if country == \"Venezuela\" else EnglishStemmer()\n",
    "    \n",
    "    results_scores_current_svc = []\n",
    "    results_scores_current_randomforest = []\n",
    "    results_scores_current_naivebayes = []\n",
    "    results_scores_current_untuned_svc = []\n",
    "    results_scores_current_untuned_randomforest = []\n",
    "    results_scores_current_untuned_naivebayes = []\n",
    "    \n",
    "    results_tuning_current_svc = []\n",
    "    results_tuning_current_randomforest = []\n",
    "    results_tuning_current_naivebayes = []\n",
    "    \n",
    "    # preprocess the data\n",
    "    data = preprocess_data(path, stops, stemmer)\n",
    "\n",
    "    # loop over seeds, load data and tune/train baseline models\n",
    "    for seed in seeds:\n",
    "        X_train_tfidf, X_test_tfidf, y_train, y_test = load_data(data, seed)\n",
    "\n",
    "        # SVC Tuned\n",
    "        print(\"SVC...\")\n",
    "        result_scores, results_tuning_current = run_svc(X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "        results_scores_current_svc.append(result_scores)\n",
    "        results_tuning_svc = results_tuning_svc.append({\"Country\": country,\n",
    "                                                \"kernel\": results_tuning_current[0],\n",
    "                                                \"C\": results_tuning_current[1],\n",
    "                                                \"class_weight\": results_tuning_current[2],\n",
    "                                                \"gamma\": results_tuning_current[3],\n",
    "                                                \"Tuning F1\": results_tuning_current[4],\n",
    "                                                \"OOS F1\": result_scores[3]}, ignore_index=True)\n",
    "        print(result_scores)\n",
    "\n",
    "        # SVC Untuned\n",
    "        print(\"SVC Untuned...\")\n",
    "        result_scores = run_svc(X_train_tfidf, X_test_tfidf, y_train, y_test, tune = False)\n",
    "        results_scores_current_untuned_svc.append(result_scores)\n",
    "        print(result_scores)\n",
    "        \n",
    "        # Random Forest Tuned\n",
    "        print(\"Random Forest...\")\n",
    "        result_scores, results_tuning_current = run_randomforest(X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "        results_scores_current_randomforest.append(result_scores)\n",
    "        results_tuning_randomforest = results_tuning_randomforest.append({\"Country\": country,\n",
    "                                                \"max_depth\": results_tuning_current[0],\n",
    "                                                \"n_estimators\": results_tuning_current[1],\n",
    "                                                \"class_weight\": results_tuning_current[2],\n",
    "                                                \"max_features\": results_tuning_current[3],\n",
    "                                                \"Tuning F1\": results_tuning_current[4],\n",
    "                                                \"OOS F1\": result_scores[3]}, ignore_index=True)\n",
    "        print(result_scores)\n",
    "        \n",
    "        # Random Forest Untuned  \n",
    "        print(\"Random Forest Untuned...\")\n",
    "        result_scores = run_randomforest(X_train_tfidf, X_test_tfidf, y_train, y_test, tune = False)\n",
    "        results_scores_current_untuned_randomforest.append(result_scores)\n",
    "        print(result_scores)\n",
    "        \n",
    "        # Naives Bayes Tuned\n",
    "        print(\"Naives Bayes...\")\n",
    "        result_scores, results_tuning_current = run_naivebayes(X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "        results_scores_current_naivebayes.append(result_scores)\n",
    "        results_tuning_naivebayes = results_tuning_naivebayes.append({\"Country\": country,\n",
    "                                                                      \"alpha\": results_tuning_current[0],\n",
    "                                                                      \"Tuning F1\": results_tuning_current[1],\n",
    "                                                                      \"OOS F1\": result_scores[3]}, ignore_index=True)\n",
    "        print(result_scores)\n",
    "        \n",
    "        # Naives Bayes Untuned  \n",
    "        print(\"Naives Bayes Untuned...\")\n",
    "        result_scores = run_naivebayes(X_train_tfidf, X_test_tfidf, y_train, y_test, tune = False)\n",
    "        results_scores_current_untuned_naivebayes.append(result_scores)\n",
    "        print(result_scores)\n",
    "        \n",
    "    # SVC Tuned\n",
    "    results_svc = results_svc.append({\"Baseline\": \"SVM\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_svc)[:, -4][0],\n",
    "                              \"Precision\": np.array(results_scores_current_svc)[:, -3][0],\n",
    "                              \"Recall\": np.array(results_scores_current_svc)[:, -2][0],\n",
    "                              \"F1\": np.array(results_scores_current_svc)[:, -1][0]}, ignore_index=True)\n",
    "    results_svc_full = results_svc_full.append({\"Baseline\": \"SVM\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_svc,\n",
    "                          \"Precision\": results_scores_current_svc,\n",
    "                          \"Recall\": results_scores_current_svc,\n",
    "                          \"F1\": results_scores_current_svc}, ignore_index=True)\n",
    "        \n",
    "    # SVC Untuned                              \n",
    "    results_svc = results_svc.append({\"Baseline\": \"SVM Untuned\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_untuned_svc)[:, -4][0],\n",
    "                              \"Precision\": np.array(results_scores_current_untuned_svc)[:, -3][0],\n",
    "                              \"Recall\": np.array(results_scores_current_untuned_svc)[:, -2][0],\n",
    "                              \"F1\": np.array(results_scores_current_untuned_svc)[:, -1][0]}, ignore_index=True)\n",
    "    results_svc_full = results_svc_full.append({\"Baseline\": \"SVM Untuned\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_untuned_svc,\n",
    "                          \"Precision\": results_scores_current_untuned_svc,\n",
    "                          \"Recall\": results_scores_current_untuned_svc,\n",
    "                          \"F1\": results_scores_current_untuned_svc}, ignore_index=True)\n",
    "        \n",
    "    # Random Forest Tuned\n",
    "    results_randomforest = results_randomforest.append({\"Baseline\": \"Random Forest\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_randomforest)[:, -4][0],\n",
    "                              \"Precision\": np.array(results_scores_current_randomforest)[:, -3][0],\n",
    "                              \"Recall\": np.array(results_scores_current_randomforest)[:, -2][0],\n",
    "                              \"F1\": np.array(results_scores_current_randomforest)[:, -1][0]}, ignore_index=True)\n",
    "    results_randomforest_full = results_randomforest_full.append({\"Baseline\": \"Random Forest\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_randomforest,\n",
    "                          \"Precision\": results_scores_current_randomforest,\n",
    "                          \"Recall\": results_scores_current_randomforest,\n",
    "                          \"F1\": results_scores_current_randomforest}, ignore_index=True) \n",
    "\n",
    "    # Random Forest Untuned\n",
    "    results_randomforest = results_randomforest.append({\"Baseline\": \"Random Forest Untuned\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_untuned_randomforest)[:, -4][0],\n",
    "                              \"Precision\": np.array(results_scores_current_untuned_randomforest)[:, -3][0],\n",
    "                              \"Recall\": np.array(results_scores_current_untuned_randomforest)[:, -2][0],\n",
    "                              \"F1\": np.array(results_scores_current_untuned_randomforest)[:, -1][0]}, ignore_index=True)\n",
    "    results_randomforest_full = results_randomforest_full.append({\"Baseline\": \"Random Forest Untuned\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_untuned_randomforest,\n",
    "                          \"Precision\": results_scores_current_untuned_randomforest,\n",
    "                          \"Recall\": results_scores_current_untuned_randomforest,\n",
    "                          \"F1\": results_scores_current_untuned_randomforest}, ignore_index=True) \n",
    "        \n",
    "    # Naive Bayes Tuned\n",
    "    results_naivebayes = results_naivebayes.append({\"Baseline\": \"Naive Bayes\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_naivebayes)[:, -4][0],\n",
    "                              \"Precision\": np.array(results_scores_current_naivebayes)[:, -3][0],\n",
    "                              \"Recall\": np.array(results_scores_current_naivebayes)[:, -2][0],\n",
    "                              \"F1\": np.array(results_scores_current_naivebayes)[:, -1][0]}, ignore_index=True)\n",
    "    results_naivebayes_full = results_naivebayes_full.append({\"Baseline\": \"Naive Bayes\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_naivebayes,\n",
    "                          \"Precision\": results_scores_current_naivebayes,\n",
    "                          \"Recall\": results_scores_current_naivebayes,\n",
    "                          \"F1\": results_scores_current_naivebayes}, ignore_index=True)    \n",
    "                              \n",
    "    # Naive Bayes Untuned\n",
    "    results_naivebayes = results_naivebayes.append({\"Baseline\": \"Naive Bayes Untuned\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_untuned_naivebayes)[:, -4][0],\n",
    "                              \"Precision\": np.array(results_scores_current_untuned_naivebayes)[:, -3][0],\n",
    "                              \"Recall\": np.array(results_scores_current_untuned_naivebayes)[:, -2][0],\n",
    "                              \"F1\": np.array(results_scores_current_untuned_naivebayes)[:, -1][0]}, ignore_index=True)\n",
    "    results_naivebayes_full = results_naivebayes_full.append({\"Baseline\": \"Naive Bayes Untuned\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_untuned_naivebayes,\n",
    "                          \"Precision\": results_scores_current_untuned_naivebayes,\n",
    "                          \"Recall\": results_scores_current_untuned_naivebayes,\n",
    "                          \"F1\": results_scores_current_untuned_naivebayes}, ignore_index=True)\n",
    "\n",
    "## Store detailed result scores\n",
    "print(results_svc)\n",
    "print(results_randomforest)\n",
    "print(results_naivebayes)\n",
    "results_svc.round(3).to_csv(\"results/svm_results.csv\", index=False)\n",
    "results_randomforest.round(3).to_csv(\"results/randomforest_results.csv\", index=False)\n",
    "results_naivebayes.round(3).to_csv(\"results/naivebayes_results.csv\", index=False)\n",
    "\n",
    "results_svc_full.round(3).to_csv(\"results/svm_results_full.csv\", index=False)\n",
    "results_randomforest_full.round(3).to_csv(\"results/randomforest_results_full.csv\", index=False)\n",
    "results_naivebayes_full.round(3).to_csv(\"results/naivebayes_results_full.csv\", index=False)\n",
    "\n",
    "# Store best hyperparameter combinations (5 tuning runs) for each country\n",
    "print(results_tuning_svc)\n",
    "print(results_tuning_randomforest)\n",
    "print(results_tuning_naivebayes)\n",
    "results_tuning_svc.round(3).to_csv(\"results/svm_results_hyperparameter.csv\", index=False)\n",
    "results_tuning_randomforest.round(3).to_csv(\"results/randomforest_results_hyperparameter.csv\", index=False)\n",
    "results_tuning_naivebayes.round(3).to_csv(\"results/naivebayes_results_hyperparameter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83692ec6",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "#load pre-trained model for correct language\n",
    "w2v_es = models.KeyedVectors.load_word2vec_format('sbw_vectors.bin', binary=True)\n",
    "w2v_en = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# initialize dictionary for countries/datasets\n",
    "countries = {\"Ghana\": \"raw/gh-tweets.csv\", \"Philippines\": \"raw/ph-tweets.csv\", \"Venezuela\": \"raw/vz-tweets.csv\"}\n",
    "\n",
    "#run several times with different param settings and seeds\n",
    "seeds = [20210101, 20210102, 20210103]\n",
    "\n",
    "#initialize result objects\n",
    "results_df = pd.DataFrame()\n",
    "results = []\n",
    "\n",
    "#loop over all countries\n",
    "for country, path in countries.items():\n",
    "\n",
    "    print(\"\\nCurrent Country: \" + country)\n",
    "\n",
    "    # initialize stopwords and stemmer in correct language\n",
    "    stops = set(stopwords.words(\"spanish\")) if country == \"Venezuela\" else set(stopwords.words(\"english\"))\n",
    "    stemmer = SpanishStemmer() if country == \"Venezuela\" else EnglishStemmer()\n",
    "    results_current = []\n",
    "\n",
    "    #load pre-trained model for correct language, to-do: aus der schleife holen\n",
    "    if country == \"Venezuela\":\n",
    "        w2v = w2v_es\n",
    "    else:\n",
    "        w2v = w2v_en\n",
    "\n",
    "    #preprocess the data\n",
    "    data = preprocess_data(path, stops, stemmer)\n",
    "\n",
    "    words=list(w2v.index_to_key)\n",
    "    vocab_len = len(w2v)\n",
    "    \n",
    "    i=1\n",
    "\n",
    "    for seed in seeds:\n",
    "\n",
    "        print(\"Run {i}/3\".format(i=i))\n",
    "\n",
    "        #iterate through different random train test splits to capture model variation\n",
    "        X_train_vec, X_train_tfidf, \\\n",
    "        X_test_vec, X_test_tfidf, \\\n",
    "        y_train_vec, y_test = embedding_transform(data, w2v,words, seed)\n",
    "        \n",
    "        tuner = tune_model_cv(X_train_vec, y_train_vec, model= country+str(seed), runs=2, epochs=200)\n",
    "        \n",
    "        #build model with best params\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        model = tuner.hypermodel.build(best_hp)\n",
    "        \n",
    "        #set class weight\n",
    "        ratio_1 = 1.0 - len(y_train_vec[y_train_vec == 1]) / float(len(y_train_vec))  ## ratio of violence instances\n",
    "        ratio_0 = 1.0 - ratio_1\n",
    "        class_weight = {0: ratio_0, 1: ratio_1}\n",
    "\n",
    "        #fit model\n",
    "        model.fit([X_train_vec, X_train_vec, X_train_vec], y_train_vec, epochs=200, batch_size=64, class_weight=class_weight)\n",
    "\n",
    "        #classify sequences\n",
    "        y_pred = model.predict([X_test_vec, X_test_vec, X_test_vec])\n",
    "        y_pred =(y_pred>0.5)\n",
    "\n",
    "        results.append(best_hp+[print_stats(y_test, y_pred, model = \"{c}_CNN_{p}\".format(p=\"tuned params\", c=country))])\n",
    "        pd.DataFrame(results, columns=[\"parameters\", \"model\", \"accuracy\", \"precision\", \"recall\", \"f1\"]).to_csv(\"temp_results_{c}_run_{p}.csv\".format(p=i, c=country))\n",
    "            \n",
    "        print(results)\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "#combine all results and calculate summary statistics\n",
    "results_df = pd.DataFrame(results, columns=[\"parameters\", \"model\", \"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "cnn_results.to_csv(\"results.csv\")\n",
    "cnn_results = results_df.groupby(results_df[\"model\"]).agg([np.mean, np.std])\n",
    "cnn_results.to_csv(\"final_results.csv\")\n",
    "\n",
    "print(cnn_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef27087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
