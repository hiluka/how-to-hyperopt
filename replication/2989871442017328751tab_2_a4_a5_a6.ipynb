{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9a993c4",
   "metadata": {},
   "source": [
    "# The Role of Hyperparameters in Machine Learning Models and How to Tune Them (PSRM, 2023)\n",
    "### Christian Arnold, Luka Biedebach, Andreas KÃ¼pfer, and Marcel Neunhoeffer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef42d16a",
   "metadata": {},
   "source": [
    "### *Code to replicate information depicted in Table 2, A4, A5, and A6*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf84eeb",
   "metadata": {},
   "source": [
    "### Naive Bayes, Random Forest, and SVM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ec5ba28",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaskuepfer/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current Country: Venezuela\n",
      "SVC...\n",
      "Fitting 5 folds for each of 484 candidates, totalling 2420 fits\n",
      "Best Tuning Score is 0.5377622377622379 with params {'svc__C': 1.0, 'svc__class_weight': 'balanced', 'svc__gamma': 0.1, 'svc__kernel': 'rbf', 'svc__random_state': 20211010}\n",
      "[0.9191090269636577, 0.36585365853658536, 0.6382978723404256, 0.46511627906976744]\n",
      "SVC Untuned...\n",
      "[0.9460726846424384, 0.6666666666666666, 0.0425531914893617, 0.08]\n",
      "Random Forest...\n",
      "Fitting 5 folds for each of 660 candidates, totalling 3300 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# Random Forest Tuned\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandom Forest...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 82\u001b[0m result_scores, results_tuning_current \u001b[38;5;241m=\u001b[39m run_randomforest(X_train_tfidf, X_test_tfidf, y_train, y_test)\n\u001b[1;32m     83\u001b[0m results_scores_current_randomforest\u001b[38;5;241m.\u001b[39mappend(result_scores)\n\u001b[1;32m     84\u001b[0m results_tuning_randomforest \u001b[38;5;241m=\u001b[39m results_tuning_randomforest\u001b[38;5;241m.\u001b[39mappend({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m\"\u001b[39m: country,\n\u001b[1;32m     85\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m: results_tuning_current[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     86\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m\"\u001b[39m: results_tuning_current[\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     87\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass_weight\u001b[39m\u001b[38;5;124m\"\u001b[39m: results_tuning_current[\u001b[38;5;241m2\u001b[39m],\n\u001b[1;32m     88\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_features\u001b[39m\u001b[38;5;124m\"\u001b[39m: results_tuning_current[\u001b[38;5;241m3\u001b[39m],\n\u001b[1;32m     89\u001b[0m                                         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTuning F1\u001b[39m\u001b[38;5;124m\"\u001b[39m: results_tuning_current[\u001b[38;5;241m4\u001b[39m]}, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Desktop/Data Science/MMDS/UML Hiwi Marcel_Chris/how-to-hyperopt/replication/functions.py:241\u001b[0m, in \u001b[0;36mrun_randomforest\u001b[0;34m(X_train_tfidf, X_test_tfidf, y_train, y_test, tune)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;66;03m# Perform grid search on isolated validation set\u001b[39;00m\n\u001b[1;32m    240\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(pipeline, param_grid, cv\u001b[38;5;241m=\u001b[39mstratified_5_fold_cv, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 241\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_tfidf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# get the best parameter setting\u001b[39;00m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Tuning Score is \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m with params \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(grid_search\u001b[38;5;241m.\u001b[39mbest_score_,\n\u001b[1;32m    246\u001b[0m                                                     grid_search\u001b[38;5;241m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    869\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    870\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    871\u001b[0m     )\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 875\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    879\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:1375\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1374\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1375\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:822\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    815\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    817\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    818\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    819\u001b[0m         )\n\u001b[1;32m    820\u001b[0m     )\n\u001b[0;32m--> 822\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    844\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/joblib/parallel.py:1056\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1053\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/joblib/parallel.py:935\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 935\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    936\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/concurrent/futures/_base.py:441\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 441\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    444\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.9/threading.py:312\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 312\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    314\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from functions import load_data, preprocess_data, run_svc, run_dummy, run_randomforest, run_naivebayes\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import EnglishStemmer, SpanishStemmer\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# set 5 different seeds for reproducibility\n",
    "seeds = [20210101, 20210102, 20210103, 20210104, 20210105]\n",
    "\n",
    "# initialize dictionary for countries/datasets\n",
    "countries = {\"Venezuela\": \"raw/vz-tweets 2.csv\", \"Ghana\": \"raw/gh-tweets 2.csv\", \"Philippines\": \"raw/ph-tweets 2.csv\"}\n",
    "\n",
    "# define dataframe to store results\n",
    "results_svc = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "results_svc_full = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "results_randomforest = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "results_randomforest_full = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "results_naivebayes = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "results_naivebayes_full = pd.DataFrame(\n",
    "    columns=[\"Baseline\", \"Country\", \"Accuracy\", \"Precision\", \"Recall\", \"F1\"])\n",
    "\n",
    "results_tuning_svc = pd.DataFrame(columns=[\"Country\", \"kernel\", \"C\", \"class_weight\", \"gamma\", \"Tuning F1\"])\n",
    "results_tuning_randomforest = pd.DataFrame(columns=[\"Country\", \"max_depth\", \"n_estimators\", \"class_weight\", \"max_features\", \"Tuning F1\"])\n",
    "results_tuning_naivebayes = pd.DataFrame(columns=[\"Country\", \"alpha\"])\n",
    "\n",
    "# loop over all countries\n",
    "\n",
    "for country, path in countries.items():\n",
    "    print(\"\\nCurrent Country: \" + country)\n",
    "    # initialize stopwords and stemmer in correct language\n",
    "    stops = set(stopwords.words(\"spanish\")) if country == \"Venezuela\" else set(stopwords.words(\"english\"))\n",
    "    stemmer = SpanishStemmer() if country == \"Venezuela\" else EnglishStemmer()\n",
    "    \n",
    "    results_scores_current_svc = []\n",
    "    results_scores_current_randomforest = []\n",
    "    results_scores_current_naivebayes = []\n",
    "    results_scores_current_untuned_svc = []\n",
    "    results_scores_current_untuned_randomforest = []\n",
    "    results_scores_current_untuned_naivebayes = []\n",
    "    \n",
    "    results_tuning_current_svc = []\n",
    "    results_tuning_current_randomforest = []\n",
    "    results_tuning_current_naivebayes = []\n",
    "    \n",
    "    # preprocess the data\n",
    "    data = preprocess_data(path, stops, stemmer)\n",
    "\n",
    "    # loop over seeds, load data and tune/train baseline models\n",
    "    for seed in seeds:\n",
    "        X_train_tfidf, X_test_tfidf, y_train, y_test = load_data(data, seed)\n",
    "\n",
    "        # SVC Tuned\n",
    "        print(\"SVC...\")\n",
    "        result_scores, results_tuning_current = run_svc(X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "        results_scores_current_svc.append(result_scores)\n",
    "        results_tuning_svc = results_tuning_svc.append({\"Country\": country,\n",
    "                                                \"kernel\": results_tuning_current[0],\n",
    "                                                \"C\": results_tuning_current[1],\n",
    "                                                \"class_weight\": results_tuning_current[2],\n",
    "                                                \"gamma\": results_tuning_current[3],\n",
    "                                                \"Tuning F1\": results_tuning_current[4]}, ignore_index=True)\n",
    "        print(result_scores)\n",
    "\n",
    "        # SVC Untuned\n",
    "        print(\"SVC Untuned...\")\n",
    "        result_scores = run_svc(X_train_tfidf, X_test_tfidf, y_train, y_test, tune = False)\n",
    "        results_scores_current_untuned_svc.append(result_scores)\n",
    "        print(result_scores)\n",
    "        \n",
    "        # Random Forest Tuned\n",
    "        print(\"Random Forest...\")\n",
    "        result_scores, results_tuning_current = run_randomforest(X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "        results_scores_current_randomforest.append(result_scores)\n",
    "        results_tuning_randomforest = results_tuning_randomforest.append({\"Country\": country,\n",
    "                                                \"max_depth\": results_tuning_current[0],\n",
    "                                                \"n_estimators\": results_tuning_current[1],\n",
    "                                                \"class_weight\": results_tuning_current[2],\n",
    "                                                \"max_features\": results_tuning_current[3],\n",
    "                                                \"Tuning F1\": results_tuning_current[4]}, ignore_index=True)\n",
    "        print(result_scores)\n",
    "        \n",
    "        # Random Forest Untuned  \n",
    "        print(\"Random Forest Untuned...\")\n",
    "        result_scores = run_randomforest(X_train_tfidf, X_test_tfidf, y_train, y_test, tune = False)\n",
    "        results_scores_current_untuned_randomforest.append(result_scores)\n",
    "        print(result_scores)\n",
    "        \n",
    "        # Naives Bayes Tuned\n",
    "        print(\"Naives Bayes...\")\n",
    "        result_scores, results_tuning_current = run_naivebayes(X_train_tfidf, X_test_tfidf, y_train, y_test)\n",
    "        results_scores_current_naivebayes.append(result_scores)\n",
    "        results_tuning_naivebayes = results_tuning_naivebayes.append({\"Country\": country,\n",
    "                                                                      \"alpha\": results_tuning_current[0],\n",
    "                                                                      \"Tuning F1\": results_tuning_current[1]}, ignore_index=True)\n",
    "        print(result_scores)\n",
    "        \n",
    "        # Naives Bayes Untuned  \n",
    "        print(\"Naives Bayes Untuned...\")\n",
    "        result_scores = run_naivebayes(X_train_tfidf, X_test_tfidf, y_train, y_test, tune = False)\n",
    "        results_scores_current_untuned_naivebayes.append(result_scores)\n",
    "        print(result_scores)\n",
    "        \n",
    "    # SVC Tuned\n",
    "    results_svc = results_svc.append({\"Baseline\": \"SVM\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_svc)[:, -4][0],\n",
    "                              \"Accuracy Std. Dev.\": 0,\n",
    "                              \"Precision\": np.array(results_scores_current_svc)[:, -3][0],\n",
    "                              \"Precision Std. Dev.\": 0,\n",
    "                              \"Recall\": np.array(results_scores_current_svc)[:, -2][0],\n",
    "                              \"Recall Std. Dev.\": 0,\n",
    "                              \"F1\": np.array(results_scores_current_svc)[:, -1][0],\n",
    "                              \"F1 Std. Dev.\": 0}, ignore_index=True)\n",
    "    results_svc_full = results_svc_full.append({\"Baseline\": \"SVM\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_svc,\n",
    "                          \"Precision\": results_scores_current_svc,\n",
    "                          \"Recall\": results_scores_current_svc,\n",
    "                          \"F1\": results_scores_current_svc}, ignore_index=True)\n",
    "        \n",
    "    # SVC Untuned                              \n",
    "    results_svc = results_svc.append({\"Baseline\": \"SVM Untuned\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_untuned_svc)[:, -4][0],\n",
    "                              \"Accuracy Std. Dev.\": 0,\n",
    "                              \"Precision\": np.array(results_scores_current_untuned_svc)[:, -3][0],\n",
    "                              \"Precision Std. Dev.\": 0,\n",
    "                              \"Recall\": np.array(results_scores_current_untuned_svc)[:, -2][0],\n",
    "                              \"Recall Std. Dev.\": 0,\n",
    "                              \"F1\": np.array(results_scores_current_untuned_svc)[:, -1][0],\n",
    "                              \"F1 Std. Dev.\": 0}, ignore_index=True)\n",
    "    results_svc_full = results_svc_full.append({\"Baseline\": \"SVM Untuned\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_untuned_svc,\n",
    "                          \"Precision\": results_scores_current_untuned_svc,\n",
    "                          \"Recall\": results_scores_current_untuned_svc,\n",
    "                          \"F1\": results_scores_current_untuned_svc}, ignore_index=True)\n",
    "        \n",
    "    # Random Forest Tuned\n",
    "    results_randomforest = results_randomforest.append({\"Baseline\": \"Random Forest\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_randomforest)[:, -4][0],\n",
    "                              \"Accuracy Std. Dev.\": 0,\n",
    "                              \"Precision\": np.array(results_scores_current_randomforest)[:, -3][0],\n",
    "                              \"Precision Std. Dev.\": 0,\n",
    "                              \"Recall\": np.array(results_scores_current_randomforest)[:, -2][0],\n",
    "                              \"Recall Std. Dev.\": 0,\n",
    "                              \"F1\": np.array(results_scores_current_randomforest)[:, -1][0],\n",
    "                              \"F1 Std. Dev.\": 0}, ignore_index=True)\n",
    "    results_randomforest_full = results_randomforest_full.append({\"Baseline\": \"Random Forest\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_randomforest,\n",
    "                          \"Precision\": results_scores_current_randomforest,\n",
    "                          \"Recall\": results_scores_current_randomforest,\n",
    "                          \"F1\": results_scores_current_randomforest}, ignore_index=True) \n",
    "\n",
    "    # Random Forest Untuned\n",
    "    results_randomforest = results_randomforest.append({\"Baseline\": \"Random Forest Untuned\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_untuned_randomforest)[:, -4][0],\n",
    "                              \"Accuracy Std. Dev.\": 0,\n",
    "                              \"Precision\": np.array(results_scores_current_untuned_randomforest)[:, -3][0],\n",
    "                              \"Precision Std. Dev.\": 0,\n",
    "                              \"Recall\": np.array(results_scores_current_untuned_randomforest)[:, -2][0],\n",
    "                              \"Recall Std. Dev.\": 0,\n",
    "                              \"F1\": np.array(results_scores_current_untuned_randomforest)[:, -1][0],\n",
    "                              \"F1 Std. Dev.\": 0}, ignore_index=True)\n",
    "    results_randomforest_full = results_randomforest_full.append({\"Baseline\": \"Random Forest Untuned\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_untuned_randomforest,\n",
    "                          \"Precision\": results_scores_current_untuned_randomforest,\n",
    "                          \"Recall\": results_scores_current_untuned_randomforest,\n",
    "                          \"F1\": results_scores_current_untuned_randomforest}, ignore_index=True) \n",
    "        \n",
    "    # Naive Bayes Tuned\n",
    "    results_naivebayes = results_naivebayes.append({\"Baseline\": \"Naive Bayes\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_naivebayes)[:, -4][0],\n",
    "                              \"Accuracy Std. Dev.\": 0,\n",
    "                              \"Precision\": np.array(results_scores_current_naivebayes)[:, -3][0],\n",
    "                              \"Precision Std. Dev.\": 0,\n",
    "                              \"Recall\": np.array(results_scores_current_naivebayes)[:, -2][0],\n",
    "                              \"Recall Std. Dev.\": 0,\n",
    "                              \"F1\": np.array(results_scores_current_naivebayes)[:, -1][0],\n",
    "                              \"F1 Std. Dev.\": 0}, ignore_index=True)\n",
    "    results_naivebayes_full = results_naivebayes_full.append({\"Baseline\": \"Naive Bayes\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_naivebayes,\n",
    "                          \"Precision\": results_scores_current_naivebayes,\n",
    "                          \"Recall\": results_scores_current_naivebayes,\n",
    "                          \"F1\": results_scores_current_naivebayes}, ignore_index=True)    \n",
    "                              \n",
    "    # Naive Bayes Untuned\n",
    "    results_naivebayes = results_naivebayes.append({\"Baseline\": \"Naive Bayes Untuned\", \"Country\": country,\n",
    "                              \"Accuracy\": np.array(results_scores_current_untuned_naivebayes)[:, -4][0],\n",
    "                              \"Accuracy Std. Dev.\": 0,\n",
    "                              \"Precision\": np.array(results_scores_current_untuned_naivebayes)[:, -3][0],\n",
    "                              \"Precision Std. Dev.\": 0,\n",
    "                              \"Recall\": np.array(results_scores_current_untuned_naivebayes)[:, -2][0],\n",
    "                              \"Recall Std. Dev.\": 0,\n",
    "                              \"F1\": np.array(results_scores_current_untuned_naivebayes)[:, -1][0],\n",
    "                              \"F1 Std. Dev.\": 0}, ignore_index=True)\n",
    "    results_naivebayes_full = results_naivebayes_full.append({\"Baseline\": \"Naive Bayes Untuned\", \"Country\": country,\n",
    "                          \"Accuracy\": results_scores_current_untuned_naivebayes,\n",
    "                          \"Precision\": results_scores_current_untuned_naivebayes,\n",
    "                          \"Recall\": results_scores_current_untuned_naivebayes,\n",
    "                          \"F1\": results_scores_current_untuned_naivebayes}, ignore_index=True)\n",
    "\n",
    "## Store detailed result scores\n",
    "print(results_svc)\n",
    "print(results_randomforest)\n",
    "print(results_naivebayes)\n",
    "results_svc.round(3).to_csv(\"svm_results.csv\", index=False)\n",
    "results_randomforest.round(3).to_csv(\"randomforest_results.csv\", index=False)\n",
    "results_naivebayes.round(3).to_csv(\"naivebayes_results.csv\", index=False)\n",
    "\n",
    "results_svc_full.round(3).to_csv(\"svm_results_full.csv\", index=False)\n",
    "results_randomforest_full.round(3).to_csv(\"randomforest_results_full.csv\", index=False)\n",
    "results_naivebayes_full.round(3).to_csv(\"naivebayes_results_full.csv\", index=False)\n",
    "\n",
    "# Store best hyperparameter combinations (5 tuning runs) for each country\n",
    "print(results_tuning_svc)\n",
    "print(results_tuning_randomforest)\n",
    "print(results_tuning_naivebayes)\n",
    "results_tuning_svc.round(3).to_csv(\"svm_results_hyperparameter.csv\", index=False)\n",
    "results_tuning_randomforest.round(3).to_csv(\"randomforest_results_hyperparameter.csv\", index=False)\n",
    "results_tuning_naivebayes.round(3).to_csv(\"naivebayes_results_hyperparameter.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83692ec6",
   "metadata": {},
   "source": [
    "### CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1bf436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "import keras_tuner\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling1D, GlobalMaxPooling2D, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from keras_tuner import HyperModel, Objective\n",
    "from keras_tuner.tuners import RandomSearch, Hyperband\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, concatenate\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from gensim import models\n",
    "import gensim.downloader as api\n",
    "\n",
    "from functions import *\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "#load pre-trained model for correct language\n",
    "w2v_es = models.KeyedVectors.load_word2vec_format('sbw_vectors.bin', binary=True)\n",
    "w2v_en = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# initialize dictionary for countries/datasets\n",
    "countries = {\"Ghana\": \"raw/gh-tweets.csv\", \"Philippines\": \"raw/ph-tweets.csv\", \"Venezuela\": \"raw/vz-tweets.csv\"}\n",
    "\n",
    "#run several times with different param settings and seeds\n",
    "seeds = [20210101, 20210102, 20210103]\n",
    "\n",
    "#initialize result objects\n",
    "results_df = pd.DataFrame()\n",
    "results = []\n",
    "\n",
    "#loop over all countries\n",
    "for country, path in countries.items():\n",
    "\n",
    "    print(\"\\nCurrent Country: \" + country)\n",
    "\n",
    "    # initialize stopwords and stemmer in correct language\n",
    "    stops = set(stopwords.words(\"spanish\")) if country == \"Venezuela\" else set(stopwords.words(\"english\"))\n",
    "    stemmer = SpanishStemmer() if country == \"Venezuela\" else EnglishStemmer()\n",
    "    results_current = []\n",
    "\n",
    "    #load pre-trained model for correct language, to-do: aus der schleife holen\n",
    "    if country == \"Venezuela\":\n",
    "        w2v = w2v_es\n",
    "    else:\n",
    "        w2v = w2v_en\n",
    "\n",
    "    #preprocess the data\n",
    "    data = preprocess_data(path, stops, stemmer)\n",
    "\n",
    "    words=list(w2v.index_to_key)\n",
    "    vocab_len = len(w2v)\n",
    "    \n",
    "    i=1\n",
    "\n",
    "    for seed in seeds:\n",
    "\n",
    "        print(\"Run {i}/3\".format(i=i))\n",
    "\n",
    "        #iterate through different random train test splits to capture model variation\n",
    "        X_train_vec, X_train_tfidf, \\\n",
    "        X_test_vec, X_test_tfidf, \\\n",
    "        y_train_vec, y_test = embedding_transform(data, w2v,words, seed)\n",
    "        \n",
    "        tuner = tune_model_cv(X_train_vec, y_train_vec, model= country+str(seed), runs=50, epochs=200)\n",
    "        \n",
    "        #build model with best params\n",
    "        best_hp = tuner.get_best_hyperparameters()[0]\n",
    "        model = tuner.hypermodel.build(best_hp)\n",
    "        \n",
    "        #set class weight\n",
    "        ratio_1 = 1.0 - len(y_train_vec[y_train_vec == 1]) / float(len(y_train_vec))  ## ratio of violence instances\n",
    "        ratio_0 = 1.0 - ratio_1\n",
    "        class_weight = {0: ratio_0, 1: ratio_1}\n",
    "\n",
    "        #fit model\n",
    "        model.fit([X_train_vec, X_train_vec, X_train_vec], y_train_vec, epochs=200, batch_size=64, class_weight=class_weight)\n",
    "\n",
    "        #classify sequences\n",
    "        y_pred = model.predict([X_test_vec, X_test_vec, X_test_vec])\n",
    "        y_pred =(y_pred>0.5)\n",
    "\n",
    "        results.append(print_stats(y_test, y_pred, model = \"{c}_CNN_{p}\".format(p=\"tuned params\", c=country)))\n",
    "        pd.DataFrame(results, columns=[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1\"]).to_csv(\"temp_results_{c}_run_{p}.csv\".format(p=i, c=country))\n",
    "            \n",
    "        print(results)\n",
    "        \n",
    "        i+=1\n",
    "        \n",
    "#combine all results and calculate summary statistics\n",
    "results_df = pd.DataFrame(results, columns=[\"model\", \"accuracy\", \"precision\", \"recall\", \"f1\"])\n",
    "results_df.to_pickle(\"results.pkl\")\n",
    "cnn_results = results_df.groupby(results_df[\"model\"]).agg([np.mean, np.std])\n",
    "cnn_results.to_csv(\"final_results.csv\")\n",
    "\n",
    "print(cnn_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
